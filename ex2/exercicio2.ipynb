{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Nome**: M - **NUSP**: "
      ],
      "metadata": {
        "id": "ruNQt07m14JM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício 2"
      ],
      "metadata": {
        "id": "EW0l5hBseYe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multilayer Perceptron\n"
      ],
      "metadata": {
        "id": "ynUmT9CUqq7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deve-se implementar uma rede multilayer perceptron e utilizá-la para resolver dois problemas (XOR e Auto-encoder).\n",
        "\n",
        "Uma rede de perceptrons multicamada é capaz de lidar com tais tipos de problemas não linearmente separáveis.\n",
        "\n",
        "No entanto, em uma rede multicamadas, o erro da saída recebe influência indireta da saída de todos os outros neurônios da rede. Portanto, deve-se modificar os pesos da camada de saída para as camadas anteriores, ocorrendo assim o processo de *backpropagation* do erro.\n",
        "\n",
        "O algoritmo *backpropagation* corrige os pesos na direção de otimização da função de custo, que no caso desta implementação é (saída esperada - saída predita)\n",
        "\n",
        "Para realizar tal otimização, calcula-se o gradiente descendente. O calculo dos gradientes foi realizado seguindo a regra delta:\n",
        "\n",
        "$\\delta_{0} = error * \\dfrac{d}{dx}\\varphi(S_{n})$\n",
        "\n",
        "$\\delta_{i} = delta_{i-1} \\cdot W^{T}_{i} \\cdot \\dfrac{d}{dx}\\varphi(S_{i}), \\; i = 1,2,3,...,n-1$\n",
        "\n",
        "em que $\\varphi(\\cdot)$ é a função de ativação, $S_{i}$ é o vetor de *output* da camada $i$, $W_{i}$ são os pesos da camada $i$\n",
        "\n",
        "\n",
        "Abaixo segue a implementação da rede MLP."
      ],
      "metadata": {
        "id": "h2BJod8plVkg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mm1-kBFadpHr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import exp, random\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de ativação sigmoid\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "# Derivada da função sigmoid\n",
        "def derivative_sigmoid(x):\n",
        "  return x * (1 - x)\n",
        "\n",
        "# Função de ativação tanh\n",
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "# Derivada da função de ativação tanh\n",
        "def derivative_tanh(x):\n",
        "  # na backpropagation o valor aqui recebido sera o de tanh(x)\n",
        "  return 1 - np.power(x, 2)\n",
        "\n",
        "# Função de ativação Rectified Linear Unit\n",
        "def reLU(x):\n",
        "  np.maximum(0, x)\n",
        "\n",
        "# Derivada da função ReLU\n",
        "def derivative_reLU(x):\n",
        "  if x > 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def vector_error(out, y):\n",
        "  # (saida esperada - saida predita)\n",
        "  return y - out\n",
        "\n",
        "\n",
        "class MLP:\n",
        "\n",
        "  def __init__(self, layers=None, seed=None):\n",
        "    if seed is not None:\n",
        "      np.random.seed(seed)\n",
        "\n",
        "    if layers == None:\n",
        "      print('Por favor defina o tamanho das camadas com a função set_camadas().\\n Ex: set_layers([tamanho_camada_entrada, tamanho_camada_escondida, tamanho_camada_saida]).')\n",
        "      return\n",
        "    else: # Os pesos para cada camadas possuem a dimensão (nro de neuronios da camada anterior x nro de neuronios da camada atual )\n",
        "      # isso ocorre pois cada neuronio da proxima camada tera a quantidade pesos igual a quantidade de saidas/neuronios da camada anterior (todas as linhas de cada coluna)\n",
        "      # enquanto teremos varios vetores de pesos para cada neuronio da camada atual (cada coluna eh um vetor peso para cada unidade do layer atual)\n",
        "      # portanto temos: cada coluna possui os pesos para cada unidade da camada atual\n",
        "      # 'a' esta sempre atrasado em 1 em relação a 'b'\n",
        "      self.weights = [random.randn(a, b) for a, b in zip(layers[:-1], layers[1:])]\n",
        "      self.bias = [random.randn(1, a) for a in layers[1:]]\n",
        "      return\n",
        "\n",
        "  def set_layers(self, layers):\n",
        "    self.weights = [random.randn(a, b) for a, b in zip(layers[:-1], layers[1:])]\n",
        "    self.bias = [random.randn(1, a) for a in layers[1:]]\n",
        "    return\n",
        "\n",
        "  # Calcula a saida da MLP dado os samples de entrada em X\n",
        "  def forward(self, X, activation_function=sigmoid):\n",
        "    # A matriz all_outputs_nn guarda todos os outputs dos layers do MLP\n",
        "    all_outputs_nn = [np.array(X)]\n",
        "    for weight, bias in zip(self.weights, self.bias):\n",
        "      # Saida de um neuronio antes da ativação = X * W + b\n",
        "      X = sigmoid(np.dot(X, weight) + bias)\n",
        "      all_outputs_nn.append(X)\n",
        "    return X, all_outputs_nn\n",
        "\n",
        "  def backpropagation(self, sample, l_rate, act_func=sigmoid, derivative_act_func=derivative_sigmoid, cost_func=vector_error):\n",
        "    x, y = sample\n",
        "    output, all_outputs_nn = self.forward(x, act_func)\n",
        "    error = cost_func(output, y)\n",
        "\n",
        "    # Devemos ajustar os pesos e bias de acordo com o erro\n",
        "    delta = [error * derivative_act_func(output)]\n",
        "    for i in range(len(all_outputs_nn)-1 , 0 , -1):\n",
        "      delta_aux = delta[len(delta)-1].dot(self.weights[i-1].T) * derivative_act_func(all_outputs_nn[i-1])\n",
        "      delta.append(delta_aux)\n",
        "    # Invertemos a ordem do array delta e ignoramos o ultimo (\"primeiro\") delta\n",
        "    delta = delta[::-1][1:]\n",
        "\n",
        "    # otimizacao dos pesos e calculo dos gradientes\n",
        "    for i,w in enumerate(self.weights):\n",
        "      if len(all_outputs_nn[i].shape) == 1:\n",
        "        all_outputs_nn[i] = all_outputs_nn[i].reshape(1, len(all_outputs_nn[i]))\n",
        "      w += (l_rate * np.dot(all_outputs_nn[i].T, delta[i]))\n",
        "\n",
        "    # otimizando bias\n",
        "    for i, b in enumerate(self.bias):\n",
        "      b += (l_rate * delta[i])\n",
        "    return\n",
        "\n",
        "  def train(self, samples, l_rate=0.5, error_lim=1e-3, cost_func=vector_error):\n",
        "    error_list = []\n",
        "    epoch = 0\n",
        "\n",
        "    while True:\n",
        "      epoch_error = []\n",
        "\n",
        "      for sample in samples:\n",
        "        x, y = sample\n",
        "        output, _ = self.forward(x)\n",
        "        epoch_error.append(cost_func(output, y))\n",
        "        self.backpropagation(sample, l_rate=l_rate)\n",
        "\n",
        "      mse = np.sum(np.square(epoch_error))/len(epoch_error)\n",
        "      error_list.append(mse)\n",
        "\n",
        "      if epoch % 5000 == 0:\n",
        "        print('Epoch: {:05d} | MSE: {:.8f}'.format(epoch, mse))\n",
        "\n",
        "      if mse < error_lim:\n",
        "        break\n",
        "\n",
        "      epoch += 1\n",
        "\n",
        "    print('Epoch: {:05d} | MSE: {:.8f}'.format(epoch, mse))\n",
        "    return error_list"
      ],
      "metadata": {
        "id": "HtULS_nBze-8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Primeiro problema (XOR)\n"
      ],
      "metadata": {
        "id": "EEFGShz-qlG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primeiro problema é o OU EXCLUSIVO (XOR).\n",
        "Dado inputs $x_1$ e $x_2$, temos o seguintes casos:\n",
        "- $x_1 = 0,\\ x_2 = 0 \\implies y = 0$\n",
        "- $x_1 = 0,\\ x_2 = 1 \\implies y = 1$\n",
        "- $x_1 = 1,\\ x_2 = 0 \\implies y = 1$\n",
        "- $x_1 = 1,\\ x_2 = 1 \\implies y = 0$\n",
        "\n",
        "A rede MLP deve ser treinada para ser capaz de predizer corretamente as saídas esperadas.\n",
        "\n",
        "A arquitetura da rede é a seguinte:\n",
        "- Camada de entrada: Número de inputs ($x_1$ e $x_2$),\n",
        "- Camada oculta: 4 neurônios\n",
        "- Camada de saída: 1 neurônio"
      ],
      "metadata": {
        "id": "ZjYrFzdZktT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xor = [([0, 0], [0]), ([0, 1], [1]), ([1, 0], [1]), ([1, 1], [0])]"
      ],
      "metadata": {
        "id": "5wwHGW0e25qS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_xor = MLP(layers=[len(xor[0]), 4, 1])"
      ],
      "metadata": {
        "id": "6YG1yobrfDjY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_epoch_xor = mlp_xor.train(samples=xor, l_rate=0.5, error_lim=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptt5yjCegnFN",
        "outputId": "fefa4172-32c6-432b-acac-87ac6daf8575"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 00000 | MSE: 0.29679574\n",
            "Epoch: 02554 | MSE: 0.00099975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, _ in xor:\n",
        "  output, _ = mlp_xor.forward(x)\n",
        "  print(f'{x} => {np.round(output)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuDlw3nYj9gX",
        "outputId": "2e9fec8e-a460-43fc-ec05-44dec4148fbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0] => [[0.]]\n",
            "[0, 1] => [[1.]]\n",
            "[1, 0] => [[1.]]\n",
            "[1, 1] => [[0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segundo problema (Auto-encoder)"
      ],
      "metadata": {
        "id": "61DtqVQzqb56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um auto-encoder é uma rede na qual a saída é igual a entrada. Neste tipo de arquitetura, busca-se realizar um mapeamento dos atributos de entrada em uma camada intermediária com menos neurônios do que o número de entradas (no caso deste exercício, a camada intermediária de mapeamento contém $\\log_{2}N$ neurônios, com $N$ sendo o tamanho da entrada)."
      ],
      "metadata": {
        "id": "d754-ZNRk0gK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Id8\n",
        "\n",
        "Resolvendo o problema do autoassociador para uma matriz identidade $I_{8 \\times 8}$."
      ],
      "metadata": {
        "id": "lYmVP5nSwJMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Id8 = [(np.identity(8).flatten(), np.identity(8).flatten())]\n",
        "#print(Id8)\n",
        "x, y = Id8[0]"
      ],
      "metadata": {
        "id": "wbdBveiExtgO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_id8 = MLP(layers=[len(x), int(np.log2(len(x))), len(x)])"
      ],
      "metadata": {
        "id": "x8y598e0q4fy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_epoch_id8 = mlp_id8.train(samples=Id8, l_rate=0.5, error_lim=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcl1cbK6sQZu",
        "outputId": "02c3eadb-f64a-4e78-9d60-087aea4c8ece"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 00000 | MSE: 20.98008839\n",
            "Epoch: 05000 | MSE: 0.00306995\n",
            "Epoch: 10000 | MSE: 0.00154756\n",
            "Epoch: 15000 | MSE: 0.00103812\n",
            "Epoch: 15581 | MSE: 0.00099998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, _ in Id8:\n",
        "  output, _ = mlp_id8.forward(x)\n",
        "  print(f'Saida esperada:\\n {x.reshape(8,8)}\\n Saida da MLP (depois de arredondado):\\n {np.round(output.reshape(8,8))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyT9Oux7tnpm",
        "outputId": "41fa72d2-0573-4baa-c1ce-e2c7497a5a17"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saida esperada:\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            " Saida da MLP (depois de arredondado):\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Id15\n",
        "\n",
        "Resolvendo o problema do autoassociador para uma matriz identidade $I_{15 \\times 15}$."
      ],
      "metadata": {
        "id": "A2H1igjfwNzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Id15 = [(np.identity(15).flatten(), np.identity(15).flatten())]\n",
        "#print(Id15)\n",
        "x, y = Id15[0]"
      ],
      "metadata": {
        "id": "r9b6yIafwRkn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_id15 = MLP(layers=[len(x), int(np.log2(len(x))), len(x)])"
      ],
      "metadata": {
        "id": "e2vi-qWawXCN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_epoch_id15 = mlp_id15.train(samples=Id15, l_rate=0.5, error_lim=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFnP7fL4wat5",
        "outputId": "93bbbcdc-eab3-481d-8c29-ab0a459f265d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 00000 | MSE: 84.51331461\n",
            "Epoch: 05000 | MSE: 0.00608632\n",
            "Epoch: 10000 | MSE: 0.00308023\n",
            "Epoch: 15000 | MSE: 0.00206910\n",
            "Epoch: 20000 | MSE: 0.00155945\n",
            "Epoch: 25000 | MSE: 0.00125185\n",
            "Epoch: 30000 | MSE: 0.00104588\n",
            "Epoch: 31396 | MSE: 0.00099998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, _ in Id15:\n",
        "  output, _ = mlp_id15.forward(x)\n",
        "  print(f'Saida esperada:\\n {x.reshape(15,15)}\\n Saida da MLP (depois de arredondado):\\n {np.round(output.reshape(15,15))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k77B3Pevwg1z",
        "outputId": "9c972411-8b4e-41a3-fc16-41da17518325"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saida esperada:\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            " Saida da MLP (depois de arredondado):\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    }
  ]
}